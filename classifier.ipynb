{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, learning_curve, ShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(train, test, num_components):\n",
    "    \n",
    "    pca = PCA(n_components=num_components)\n",
    "    pca.fit(train_X)\n",
    "    return pca.fit_transform(train), pca.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda(train_X, train_Y, test):\n",
    "    \n",
    "    lda = LDA()\n",
    "    lda.fit(train_X, train_Y)\n",
    "    return lda.transform(train_X), lda.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(train_X_pca, train_X_lda, train_X_lpca, train_Y, test_X_pca, test_X_lda, test_X_lpca, test_Y, t, C, penalty):\n",
    "    \n",
    "    hyp_param = dict(C=C, penalty=penalty)\n",
    "    print(\"Hyperparameters: \", hyp_param)\n",
    "    clf = LogisticRegression()\n",
    "\n",
    "    hyperparam(train_X_pca, train_Y, clf, hyp_param, test_X_pca, test_Y, t, \"Logistic Regression PCA\")\n",
    "    hyperparam(train_X_lda, train_Y, clf, hyp_param, test_X_lda, test_Y, t, \"Logistic Regression LDA\")\n",
    "    hyperparam(train_X_lpca, train_Y, clf, hyp_param, test_X_lpca, test_Y, t, \"Logistic Regression PCA + LDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_lin(train_X_pca, train_X_lda, train_X_lpca, train_Y, test_X_pca, test_X_lda, test_X_lpca, test_Y, t, C, kernel, max_iter):\n",
    "    \n",
    "    hyp_param = dict(C=C, kernel=kernel, max_iter=max_iter)\n",
    "    clf = SVC()\n",
    "\n",
    "    hyperparam(train_X_pca, train_Y, clf, hyp_param, test_X_pca, test_Y, t, \"SVM PCA\", cv=2)\n",
    "    hyperparam(train_X_lda, train_Y, clf, hyp_param, test_X_lda, test_Y, t, \"SVM LDA\", cv=2)\n",
    "    hyperparam(train_X_lpca, train_Y, clf, hyp_param, test_X_lpca, test_Y, t, \"SVM PCA + LDA\", cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec_tree(train_X_pca, train_X_lda, train_X_lpca, train_Y, test_X_pca, test_X_lda, test_X_lpca, test_Y, t, max_features, min_samples_split, min_samples_leaf):\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 5)]\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 5)]\n",
    "    max_depth.append(None)\n",
    "    hyp_param = dict(max_features=max_features, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "    print(hyp_param)\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "    hyperparam(train_X_pca, train_Y, clf, hyp_param, test_X_pca, test_Y, t, \"Decision Tree PCA\", cv=3)\n",
    "    hyperparam(train_X_lda, train_Y, clf, hyp_param, test_X_lda, test_Y, t, \"Decision Tree LDA\", cv=3)\n",
    "    hyperparam(train_X_lpca, train_Y, clf, hyp_param, test_X_lpca, test_Y, t, \"Decision Tree PCA + LDA\", cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(train_X_pca, train_X_lda, train_X_lpca, train_Y, test_X_pca, test_X_lda, test_X_lpca, test_Y, t, hidden_layer_sizes, max_iter, alpha, learning_rate_init):\n",
    "\n",
    "    hidden_layer_sizes = [(256,), (256, 128)]\n",
    "    max_iter = [1000]\n",
    "    alpha = np.logspace(-5, -1, 5)\n",
    "    learning_rate_init = [1e-3, 1e-4, 1e-5]\n",
    "    hyp_param = dict(hidden_layer_sizes=hidden_layer_sizes, max_iter=max_iter, alpha=alpha, learning_rate_init=learning_rate_init)\n",
    "    print(hyp_param)\n",
    "    clf = MLPClassifier()\n",
    "\n",
    "    hyperparam(train_X_pca, train_Y, clf, hyp_param, test_X_pca, test_Y, t, \"MLP PCA\", cv=3)\n",
    "    hyperparam(train_X_lda, train_Y, clf, hyp_param, test_X_lda, test_Y, t, \"MLP LDA\", cv=3)\n",
    "    hyperparam(train_X_lpca, train_Y, clf, hyp_param, test_X_lpca, test_Y, t, \"MLP PCA + LDA\", cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph(estimator, title, X, y, cv=None, n_jobs=None, train_size=np.linspace(.1, 1.0, 5)):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Trained Examples\")\n",
    "    plt.ylabel(\"Points\")\n",
    "    train_size, train_scr, test_scr = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_size)\n",
    "    train_scr_mean = np.mean(train_scr, axis=1)\n",
    "    train_scr_std = np.std(train_scr, axis=1)\n",
    "    test_scr_mean = np.mean(test_scr, axis=1)\n",
    "    test_scr_std = np.std(test_scr, axis=1)\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_size, (train_scr_mean - train_scr_std), (train_scr_mean + train_scr_std), alpha=0.1, color=\"b\")\n",
    "    plt.fill_between(train_size, (test_scr_mean - test_scr_std), (test_scr_mean + test_scr_std), alpha=0.1, color=\"y\")\n",
    "    plt.plot(train_size, train_scr_mean, 'o-', color=\"b\", label=\"Training Points\")\n",
    "    plt.plot(train_size, test_scr_mean, 'o-', color=\"y\", label=\"Cross-validation score\")\n",
    "    # plt.legend(loc=\"best\")\n",
    "    plt.savefig(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparam(train_X, train_Y, estimator, params, test_X, test_Y, t, title, cv=3):\n",
    "    \n",
    "    clf = GridSearchCV(estimator, params, cv=cv, verbose=0)\n",
    "    model = clf.fit(train_X, train_Y)\n",
    "    train_score = model.score(train_X, train_Y)\n",
    "    test_score = model.score(test_X, test_Y)\n",
    "    print(\"*\"*100)\n",
    "    print(title)\n",
    "    print(\"Best Parameters\")\n",
    "    print(model.best_estimator_.get_params())\n",
    "    print(Testing Score: \", test_score)\n",
    "    graph(model, title, train_X, train_Y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3072\n",
    "t = -1\n",
    "\n",
    "(train_X, train_Y), (test_X, test_Y) = cifar10.load_data()\n",
    "train_X = train_X.reshape(t, k)\n",
    "test_X = test_X.reshape(t, k)\n",
    "train_Y = train_Y.reshape(t)\n",
    "test_Y = test_Y.reshape(t)\n",
    "\n",
    "mean_train_X = np.mean(train_X, axis=0)\n",
    "mean_test_X = np.mean(test_X, axis=0)\n",
    "\n",
    "n_train = np.std(train_X, axis=0)\n",
    "n_test = np.std(test_X, axis=0)\n",
    "\n",
    "train_X = (train_X - mean_train_X) / n_train\n",
    "test_X = (test_X - mean_test_X) / n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_pca, test_X_pca = pca(train_X, test_X, num_components=13)\n",
    "train_X_pca_lrg, test_X_pca_lrg = pca(train_X, test_X, num_components=285)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_lda, test_X_lda = lda(train_X, train_Y, test_X)\n",
    "train_X_lpca, test_X_lpca = lda(train_X_pca_lrg, train_Y, test_X_pca_lrg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR(train_X_pca, train_X_lda, train_X_lpca, train_Y, test_X_pca, test_X_lda, test_X_lpca, test_Y, t, np.logspace(-2, 4, 7), ['l2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_lin(train_X_pca, train_X_lda, train_X_lpca, train_Y, test_X_pca, test_X_lda, test_X_lpca, test_Y, t, [0.001, 0.01, 0.1, 10, 100, 1000], ['linear'], [1e4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree(train_X_pca, train_X_lda, train_X_lpca, train_Y, test_X_pca, test_X_lda, test_X_lpca, test_Y, t, ['auto', 'sqrt'], [2, 5, 10], [1, 2, 4, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp(train_X_pca, train_X_lda, train_X_lpca, train_Y, test_X_pca, test_X_lda, test_X_lpca, test_Y, t, [(256,), (256, 128)], [1000], np.logspace(-5, -1, 5), [1e-3, 1e-4, 1e-5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
